# ChengYi

Code for paper: [Efficiently Fusing Pretrained Acoustic and Linguistic Encoders for Low-resource Speech Recognition](https://arxiv.org/abs/2101.06699)

We only provide key files of our model, w2v-cif-bert, which can be reimplement based on [fairseq](https://github.com/pytorch/fairseq/tree/master/fairseq/models/wav2vec).
If you have any questions on the reimplementation, please consult yicheng2016@ia.ac.cn.
